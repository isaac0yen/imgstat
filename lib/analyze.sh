#!/usr/bin/env bash

source "$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)/utils.sh"

cmd_analyze() {
  local dir="$1"
  echo "Analyzing codebase for remote image references in $dir..."
  
  # Scan common code files for URLs
  # We extract http/https links specifically in src, href, url() contexts
  local urls=()
  
  # Read all matching files, use grep to find URLs, and sort uniquely
  # This uses a basic grep regex to find common image URL patterns.
  mapfile -t urls < <(find "$dir" \
    -type d \( -name "node_modules" -o -name ".git" -o -name "dist" -o -name "build" \) -prune -o \
    -type f \( -name "*.html" -o -name "*.jsx" -o -name "*.tsx" -o -name "*.js" -o -name "*.ts" -o -name "*.vue" -o -name "*.css" -o -name "*.scss" \) \
    -exec grep -oE "https?://[^\"')[:space:]]+" {} + 2>/dev/null | sort -u)

  if [[ ${#urls[@]} -eq 0 ]]; then
    echo "No remote URLs found in code files."
    return 0
  fi
  
  echo "Found ${#urls[@]} unique URL(s). Fetching dimensions..."
  
  # Prepare secure fetch directory
  local TEMP_DIR
  TEMP_DIR=$(mktemp -d)
  trap 'rm -rf "$TEMP_DIR"' EXIT
  
  # Output file setup
  local rules_dir="$dir/.agent/rules"
  local rules_file="$rules_dir/image_dimensions.md"
  
  mkdir -p "$rules_dir"
  
  # Write header for the agent
  cat << 'EOF' > "$rules_file"
# Codebase Remote Images

> [!NOTE]
> This file is strictly auto-generated by \`imgstat\`.
> It maps remote image URLs found in the codebase to their exact physical dimensions.
> AI assistants should use this dictionary when asked about layout constraints, native sizes, or aspect ratios of referenced images.

| Documented URL | Detected Size (W x H) |
|---|---|
EOF
  
  local processed=0
  
  for url in "${urls[@]}"; do
    # Skip obvious non-images if possible, but Cloudinary etc don't have extensions
    # so we attempt a shallow fetch for all to be safe.
    
    # 1. Fetch direct URL
    wget -q --content-disposition -P "$TEMP_DIR" "$url" || true
    
    local all_files=( "$TEMP_DIR"/* )
    local found_images=()
    
    for file in "${all_files[@]}"; do
      if [[ ! -f "$file" ]]; then continue; fi
      local mimetype
      mimetype=$(file -b --mime-type "$file" 2>/dev/null || true)
      if [[ "$mimetype" == image/* ]]; then
        found_images+=("$file")
      fi
    done
    
    # Process only the first valid image found for the URL
    if [[ ${#found_images[@]} -gt 0 ]]; then
      local file="${found_images[0]}"
      local dim
      dim=$(get_dimensions "$file" || true)
      
      if [[ -n "$dim" ]]; then
        local w="${dim% *}"
        local h="${dim#* }"
        echo "| \`$url\` | **${w}x${h}** |" >> "$rules_file"
        processed=$((processed + 1))
      fi
    fi
    
    # Clean temp dir contents for the next URL to avoid collision
    rm -rf "${TEMP_DIR:?}"/*
  done
  
  echo "Analysis complete!"
  echo "Documented $processed valid image reference(s) into: $rules_file"
  echo "This file can now be read by autonomous coding agents."
}
